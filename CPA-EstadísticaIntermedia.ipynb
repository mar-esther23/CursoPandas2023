{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0174ed1e-2e0e-435e-9de5-0b5fcf15fb8c",
   "metadata": {},
   "source": [
    "# Análisis y visualización de datos abiertos con python\n",
    "# Extra: Estadística intermedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e486cd-264d-45f1-a20a-e9f6a87d24ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Correlaciones\n",
    "\n",
    "La correlación es una medida estadística que describe la relación entre dos variables. La correlación puede ser positiva, negativa o neutra, y su valor puede variar entre -1 y 1. Una correlación positiva significa que a medida que una variable aumenta, la otra variable también tiende a aumentar. Una correlación negativa significa que a medida que una variable aumenta, la otra variable tiende a disminuir. Una correlación neutra significa que no hay una relación aparente entre las dos variables.\n",
    "\n",
    "El coeficiente de correlación de Pearson es la medida más comúnmente utilizada para calcular la correlación entre dos variables continuas. Este coeficiente varía entre -1 y 1, y se calcula dividiendo la covarianza de las dos variables por el producto de sus desviaciones estándar.\n",
    "\n",
    "Otras medidas de correlación incluyen el coeficiente de correlación de rango de Spearman y el coeficiente de correlación de rango de Kendall, que son útiles cuando las variables no siguen una distribución normal o cuando hay valores atípicos en los datos.\n",
    "\n",
    "Es importante tener en cuenta que la correlación no implica causalidad. Solo porque dos variables estén correlacionadas, no significa que una variable cause la otra. La correlación solo indica que hay una relación entre las dos variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26df721f-7e07-4f8d-a06e-7a33715e68c0",
   "metadata": {},
   "source": [
    "Para datos categóricos, se utilizan medidas de correlación distintas a las utilizadas para datos continuos. Las medidas de correlación para datos categóricos se basan en la comparación de las frecuencias observadas de las combinaciones de categorías de dos variables con las frecuencias esperadas bajo la hipótesis de independencia.\n",
    "\n",
    "Algunas de las medidas de correlación para datos categóricos más comunes incluyen:\n",
    "* Coeficiente de contingencia: mide la relación entre dos variables categóricas, tomando valores entre 0 y 1. Un valor cercano a 0 indica que las variables son independientes, mientras que un valor cercano a 1 indica una relación fuerte.\n",
    "* Coeficiente de correlación phi: es similar al coeficiente de contingencia, pero se utiliza específicamente para variables binarias (que solo tienen dos categorías).\n",
    "* Coeficiente de correlación Cramer's V: es una generalización del coeficiente de contingencia que se utiliza para variables con más de dos categorías.\n",
    "* Coeficiente de correlación de Kendall's tau-b: se utiliza para medir la relación entre dos variables ordinales (variables categóricas que tienen un orden natural).\n",
    "* Coeficiente de correlación de Spearman's rho: es similar a Kendall's tau-b, pero se utiliza para medir la relación entre dos variables ordinales o variables continuas.\n",
    "\n",
    "Es importante tener en cuenta que estas medidas de correlación solo miden la fuerza de la relación entre dos variables categóricas y no establecen causalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8575920a-5872-440a-ada9-57c2822f65f4",
   "metadata": {},
   "source": [
    "En Pandas, la función corr() se utiliza para calcular la matriz de correlación entre todas las variables de un DataFrame. Por defecto, esta función calcula la correlación de Pearson para las variables numéricas.\n",
    "\n",
    "Sin embargo, para calcular la correlación entre variables categóricas, es necesario convertir estas variables a una representación numérica. Esto se puede hacer utilizando la técnica de codificación one-hot (también conocida como codificación de variables ficticias o dummy). La codificación one-hot convierte cada categoría en una variable binaria (1 si pertenece a la categoría, 0 si no) y luego calcula la correlación de Pearson entre estas variables binarias.\n",
    "\n",
    "A continuación se muestra un ejemplo de cómo calcular la matriz de correlación entre variables categóricas utilizando Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56f4be0-c46a-41bc-8be5-ac5690f1814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear un DataFrame con variables categóricas\n",
    "df = pd.DataFrame({\n",
    "    'sexo': ['M', 'F', 'M', 'F', 'M', 'M', 'F', 'F'],\n",
    "    'grupo_sanguineo': ['A', 'O', 'B', 'O', 'A', 'AB', 'B', 'O'],\n",
    "    'enfermedad': ['no', 'si', 'no', 'si', 'no', 'si', 'no', 'si']\n",
    "})\n",
    "\n",
    "# Convertir variables categóricas a variables binarias (one-hot encoding)\n",
    "df_encoded = pd.get_dummies(df)\n",
    "\n",
    "# Calcular la matriz de correlación utilizando el coeficiente de correlación de Pearson\n",
    "correlaciones = df_encoded.corr(method='pearson')\n",
    "print(correlaciones)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e586238-1c87-427e-84e0-b61badb2100f",
   "metadata": {},
   "source": [
    "En este ejemplo, se crea un DataFrame con tres variables categóricas (sexo, grupo_sanguineo y enfermedad). Luego, se utiliza la función get_dummies() de Pandas para codificar estas variables categóricas como variables binarias.\n",
    "\n",
    "Finalmente, se calcula la matriz de correlación utilizando el coeficiente de correlación de Pearson con el método corr() de Pandas. El resultado es una matriz de correlación que muestra la correlación entre todas las variables binarias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0d8958-1bb2-4c29-a85c-04c48f781738",
   "metadata": {},
   "source": [
    "## Regresión lineal y logística\n",
    "\n",
    "### Regresión lineal\n",
    "\n",
    "La regresión lineal es una técnica de análisis estadístico utilizada para modelar la relación entre una variable dependiente (Y) y una o más variables independientes (X). En la regresión lineal, se ajusta una línea recta a los datos para encontrar la mejor estimación de la relación entre las variables.\n",
    "\n",
    "En Python, se puede realizar una regresión lineal utilizando la biblioteca de ciencia de datos y aprendizaje automático, Scikit-Learn. El siguiente es un ejemplo básico de cómo realizar una regresión lineal en Python usando Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf4a81f-eacb-4332-aca4-13573e879ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Crear datos de ejemplo\n",
    "x = np.array([1, 2, 3, 4, 5]).reshape((-1, 1))\n",
    "y = np.array([2, 3, 4, 5, 6])\n",
    "\n",
    "# Crear el objeto de regresión lineal\n",
    "modelo = LinearRegression()\n",
    "\n",
    "# Ajustar el modelo utilizando los datos de entrenamiento\n",
    "modelo.fit(x, y)\n",
    "\n",
    "# Obtener la intersección y la pendiente de la línea de regresión\n",
    "interseccion = modelo.intercept_\n",
    "pendiente = modelo.coef_\n",
    "\n",
    "# Predecir nuevos valores\n",
    "nuevos_x = np.array([6, 7, 8]).reshape((-1, 1))\n",
    "predicciones = modelo.predict(nuevos_x)\n",
    "\n",
    "# Visualizar los resultados\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, interseccion + pendiente * x, color='red')\n",
    "plt.scatter(nuevos_x, predicciones, color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add55fe-cdb6-41ee-80df-47e76f928035",
   "metadata": {},
   "source": [
    "En este ejemplo, primero se crean algunos datos de ejemplo para X e Y. Luego, se crea un objeto de regresión lineal utilizando la clase LinearRegression() de Scikit-Learn. A continuación, se ajusta el modelo utilizando los datos de entrenamiento utilizando el método fit().\n",
    "\n",
    "Después de ajustar el modelo, se pueden obtener los valores de intersección y pendiente de la línea de regresión utilizando los atributos intercept_ y coef_ del modelo. Luego, se pueden utilizar estos valores para predecir nuevos valores de Y utilizando el método predict().\n",
    "\n",
    "Finalmente, se visualizan los resultados graficando los puntos de datos originales, la línea de regresión ajustada y las predicciones de los nuevos valores en un gráfico.\n",
    "\n",
    "Es importante tener en cuenta que la regresión lineal es una técnica poderosa pero tiene ciertas suposiciones y limitaciones. Por lo tanto, siempre es importante validar el modelo y realizar un análisis de los residuos para verificar la calidad del ajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e149a-4a32-4c01-bdd6-58805e7a6a42",
   "metadata": {},
   "source": [
    "### Regresión logística\n",
    "\n",
    "La regresión logística es una técnica de modelado estadístico que se utiliza para predecir la probabilidad de que ocurra un evento binario (sí o no, verdadero o falso) en función de una o más variables independientes. A diferencia de la regresión lineal, que se utiliza para predecir valores numéricos continuos, la regresión logística se utiliza para predecir una variable categórica.\n",
    "\n",
    "En Python, se puede realizar una regresión logística utilizando la biblioteca Scikit-Learn. El siguiente es un ejemplo básico de cómo realizar una regresión logística en Python usando Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad983ed6-9bbf-4e05-aa27-d2da19a0af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Cargar el conjunto de datos de ejemplo\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Separar los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear el objeto de regresión logística\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Ajustar el modelo utilizando los datos de entrenamiento\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones sobre los datos de prueba\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "precision = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Imprimir la precisión del modelo\n",
    "print(\"Precisión del modelo: {:.2f}%\".format(precision * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f2edb0-d4d4-49db-8c9c-99ca6ef41ed8",
   "metadata": {},
   "source": [
    "En este ejemplo, se utiliza el conjunto de datos de cáncer de mama de Wisconsin, que contiene información sobre diferentes características de las células del cáncer de mama. Primero, se separan los datos en conjuntos de entrenamiento y prueba utilizando la función train_test_split() de Scikit-Learn.\n",
    "\n",
    "Luego, se crea un objeto de regresión logística utilizando la clase LogisticRegression() de Scikit-Learn. A continuación, se ajusta el modelo utilizando los datos de entrenamiento utilizando el método fit().\n",
    "\n",
    "Después de ajustar el modelo, se utilizan los datos de prueba para realizar predicciones utilizando el método predict(). Luego, se calcula la precisión del modelo utilizando la función accuracy_score() de Scikit-Learn.\n",
    "\n",
    "Finalmente, se imprime la precisión del modelo en la consola.\n",
    "\n",
    "Es importante tener en cuenta que la regresión logística también tiene suposiciones y limitaciones, por lo que siempre es importante validar el modelo y realizar un análisis de los residuos para verificar la calidad del ajuste. Además, la selección de variables y la optimización de los hiperparámetros también son importantes para mejorar el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603bdd28-db28-4966-9c3c-8923c4d82033",
   "metadata": {},
   "source": [
    "## PCA y PCoA\n",
    "\n",
    "### PCA (Análisis de Componentes Principales)\n",
    "\n",
    "PCA (Análisis de Componentes Principales) es una técnica estadística utilizada para reducir la dimensionalidad de un conjunto de datos. El PCA busca encontrar las combinaciones lineales de las variables originales que expliquen la mayor cantidad posible de la variabilidad en los datos. Estas nuevas variables, llamadas componentes principales, se ordenan en función de la cantidad de varianza que explican en los datos.\n",
    "\n",
    "La idea detrás del PCA es que, en muchos casos, los datos pueden estar altamente correlacionados entre sí y pueden ser redundantes en términos de información. Al reducir la dimensionalidad de los datos mediante el PCA, podemos eliminar esta redundancia y conservar solo las variables más informativas y significativas para el análisis.\n",
    "\n",
    "El PCA se utiliza comúnmente en diferentes campos, incluyendo la biología, la química, la física, la psicología, la economía, entre otros. En la práctica, el PCA se aplica a un conjunto de datos de alta dimensionalidad, se calculan los componentes principales, y se utilizan estos componentes para realizar análisis más simples, como clasificación, regresión o visualización.\n",
    "\n",
    "Es importante destacar que el PCA es una técnica no supervisada, es decir, no requiere etiquetas o información de respuesta para llevar a cabo la reducción de dimensionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c7effe-f2f6-467e-b067-357fa058b46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de65f7b0-4e72-4ef4-981a-20873863cd65",
   "metadata": {},
   "source": [
    "### PCoA (Análisis de Coordenadas Principales)\n",
    "\n",
    "PCoA (Análisis de Coordenadas Principales) es una técnica multivariante utilizada para explorar y visualizar la similitud o distancia entre los datos. El PCoA es similar al PCA, pero en lugar de trabajar directamente con las variables, el PCoA trabaja con una matriz de distancia o similitud que se calcula a partir de los datos originales.\n",
    "\n",
    "En el PCoA, los datos se representan en un espacio de menor dimensión (generalmente 2D o 3D) donde la distancia entre los puntos refleja la similitud o distancia entre los datos originales. El PCoA es útil para analizar datos de tipo biológico, como datos de microbioma, ecología, genómica, entre otros.\n",
    "\n",
    "La idea detrás del PCoA es reducir la complejidad de la matriz de distancia o similitud a un espacio de menor dimensión, sin perder la información relevante de las similitudes o distancias entre los datos originales. A diferencia del PCA, que busca encontrar las combinaciones lineales de las variables que expliquen la mayor cantidad posible de la variabilidad en los datos, el PCoA utiliza la información de la matriz de distancia para construir un espacio que refleje la similitud entre los datos originales.\n",
    "\n",
    "El PCoA se utiliza comúnmente en análisis de microbioma y ecología, donde se analizan las similitudes o distancias entre las comunidades microbianas o ecológicas. También se utiliza en genómica para analizar las similitudes o distancias entre los perfiles de expresión génica. El PCoA es una técnica no supervisada, es decir, no requiere etiquetas o información de respuesta para llevar a cabo el análisis y visualización de los datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
